{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "## Interpretability - Text Explainers\n\nIn this example, we use LIME and Kernel SHAP explainers to explain a text classification model.\n\nFirst we import the packages and define some UDFs and a plotting function we will need later."
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "19cbad15-bdc7-4b74-8f6b-6e6da75fec35"
                }
            }
        },
        {
            "cell_type": "code",
            "source": [
                "from pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nfrom pyspark.ml.feature import StopWordsRemover, HashingTF, IDF, Tokenizer\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom mmlspark.explainers import *\nfrom mmlspark.featurize.text import TextFeaturizer\n\nvec2array = udf(lambda vec: vec.toArray().tolist(), ArrayType(FloatType()))\nvec_access = udf(lambda v, i: float(v[i]), FloatType())"
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "a2689fb5-2425-430d-8261-6e39598b6505"
                }
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "metadata": {
                        "application/vnd.databricks.v1+output": {
                            "data": "",
                            "errorSummary": "",
                            "metadata": {},
                            "errorTraceType": null,
                            "type": "ipynbError",
                            "arguments": {}
                        }
                    },
                    "output_type": "display_data",
                    "data": {
                        "text/html": [
                            "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
                        ]
                    }
                }
            ],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "Load training data, and convert rating to binary label."
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "1f52a610-0695-48c2-9de9-e60f239dd5c7"
                }
            }
        },
        {
            "cell_type": "code",
            "source": [
                "data = (\n    spark.read.parquet(\"wasbs://publicwasb@mmlspark.blob.core.windows.net/BookReviewsFromAmazon10K.parquet\")\n    .withColumn(\"label\", (col(\"rating\") > 3).cast(LongType()))\n    .select(\"label\", \"text\")\n)\n\ndata.limit(10).toPandas()"
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "a02806b1-e0ba-4b6f-93bf-5d3eb635e43e"
                }
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "metadata": {
                        "application/vnd.databricks.v1+output": {
                            "data": "",
                            "errorSummary": "",
                            "metadata": {},
                            "errorTraceType": null,
                            "type": "ipynbError",
                            "arguments": {}
                        }
                    },
                    "output_type": "display_data",
                    "data": {
                        "text/html": [
                            "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
                        ]
                    }
                }
            ],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "We train a text classification model, and randomly sample 10 rows to explain."
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "87a536da-b4b4-4c79-b6a3-5f7b1ad7428a"
                }
            }
        },
        {
            "cell_type": "code",
            "source": [
                "train, test = data.randomSplit([0.60, 0.40])\n\npipeline = Pipeline(\n    stages=[\n        TextFeaturizer(\n            inputCol=\"text\",\n            outputCol=\"features\",\n            useStopWordsRemover=True,\n            useIDF=True,\n            minDocFreq=20,\n            numFeatures=1 << 16,\n        ),\n        LogisticRegression(maxIter=100, regParam=0.005, labelCol=\"label\", featuresCol=\"features\"),\n    ]\n)\n\nmodel = pipeline.fit(train)\n\nprediction = model.transform(test)\n\nexplain_instances = prediction.orderBy(rand()).limit(10)"
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "9a2fb867-194d-4660-b655-6373ec7272bf"
                }
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "metadata": {
                        "application/vnd.databricks.v1+output": {
                            "data": "",
                            "errorSummary": "",
                            "metadata": {},
                            "errorTraceType": null,
                            "type": "ipynbError",
                            "arguments": {}
                        }
                    },
                    "output_type": "display_data",
                    "data": {
                        "text/html": [
                            "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
                        ]
                    }
                }
            ],
            "execution_count": 0
        },
        {
            "cell_type": "code",
            "source": [
                "def plotConfusionMatrix(df, label, prediction, classLabels):\n    from mmlspark.plot import confusionMatrix\n    import matplotlib.pyplot as plt\n\n    fig = plt.figure(figsize=(4.5, 4.5))\n    confusionMatrix(df, label, prediction, classLabels)\n    display(fig)\n\n\nplotConfusionMatrix(model.transform(test), \"label\", \"prediction\", [0, 1])"
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "3a9fbdc8-9660-4337-b3eb-7c717aabf0cc"
                }
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "metadata": {
                        "application/vnd.databricks.v1+output": {
                            "data": "",
                            "errorSummary": "",
                            "metadata": {},
                            "errorTraceType": null,
                            "type": "ipynbError",
                            "arguments": {}
                        }
                    },
                    "output_type": "display_data",
                    "data": {
                        "text/html": [
                            "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
                        ]
                    }
                }
            ],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "First we use the LIME text explainer to explain the model's predicted probability for a given observation."
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "50c294f1-439a-455e-bff4-25c65822a575"
                }
            }
        },
        {
            "cell_type": "code",
            "source": [
                "lime = TextLIME(\n    model=model,\n    outputCol=\"weights\",\n    inputCol=\"text\",\n    targetCol=\"probability\",\n    targetClasses=[1],\n    tokensCol=\"tokens\",\n    samplingFraction=0.7,\n    numSamples=2000,\n)\n\nlime_results = (\n    lime.transform(explain_instances)\n    .select(\"tokens\", \"weights\", \"r2\", \"probability\", \"text\")\n    .withColumn(\"probability\", vec_access(\"probability\", lit(1)))\n    .withColumn(\"weights\", vec2array(col(\"weights\").getItem(0)))\n    .withColumn(\"r2\", vec_access(\"r2\", lit(0)))\n    .withColumn(\"tokens_weights\", arrays_zip(\"tokens\", \"weights\"))\n)\n\ndisplay(lime_results.select(\"probability\", \"r2\", \"tokens_weights\", \"text\").orderBy(col(\"probability\").desc()))"
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "63623d84-8d6d-4f5b-8e2b-83e21866fb26"
                }
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "metadata": {
                        "application/vnd.databricks.v1+output": {
                            "data": "",
                            "errorSummary": "",
                            "metadata": {},
                            "errorTraceType": null,
                            "type": "ipynbError",
                            "arguments": {}
                        }
                    },
                    "output_type": "display_data",
                    "data": {
                        "text/html": [
                            "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
                        ]
                    }
                }
            ],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "Then we use the Kernel SHAP text explainer to explain the model's predicted probability for a given observation.\n\n> Notice that we drop the base value from the SHAP output before displaying the SHAP values. The base value is the model output for an empty string."
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "de0ff3a3-fc93-4769-8b98-2fab81467fcc"
                }
            }
        },
        {
            "cell_type": "code",
            "source": [
                "shap = TextSHAP(\n    model=model,\n    outputCol=\"shaps\",\n    inputCol=\"text\",\n    targetCol=\"probability\",\n    targetClasses=[1],\n    tokensCol=\"tokens\",\n    numSamples=5000,\n)\n\nshap_results = (\n    shap.transform(explain_instances)\n    .select(\"tokens\", \"shaps\", \"r2\", \"probability\", \"text\")\n    .withColumn(\"probability\", vec_access(\"probability\", lit(1)))\n    .withColumn(\"shaps\", vec2array(col(\"shaps\").getItem(0)))\n    .withColumn(\"shaps\", slice(col(\"shaps\"), lit(2), size(col(\"shaps\"))))\n    .withColumn(\"r2\", vec_access(\"r2\", lit(0)))\n    .withColumn(\"tokens_shaps\", arrays_zip(\"tokens\", \"shaps\"))\n)\n\ndisplay(shap_results.select(\"probability\", \"r2\", \"tokens_shaps\", \"text\").orderBy(col(\"probability\").desc()))"
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "9d3fd01d-f140-465e-ae53-d3b25f246e4d"
                }
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "metadata": {
                        "application/vnd.databricks.v1+output": {
                            "data": "",
                            "errorSummary": "",
                            "metadata": {},
                            "errorTraceType": null,
                            "type": "ipynbError",
                            "arguments": {}
                        }
                    },
                    "output_type": "display_data",
                    "data": {
                        "text/html": [
                            "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
                        ]
                    }
                }
            ],
            "execution_count": 0
        }
    ],
    "metadata": {
        "application/vnd.databricks.v1+notebook": {
            "notebookName": "Interpretability - Text Explainers",
            "dashboards": [],
            "notebookMetadata": {
                "pythonIndentUnit": 2
            },
            "language": "python",
            "widgets": {},
            "notebookOrigID": 913802417841163
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}