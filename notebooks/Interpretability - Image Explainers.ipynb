{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "## Interpretability - Image Explainers\n\nIn this example, we use LIME and Kernel SHAP explainers to explain the ResNet50 model's multi-class output of an image.\n\nFirst we import the packages and define some UDFs and a plotting function we will need later."
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "7a2d7f1b-99c4-44d2-9ac5-62ca59002d61"
                }
            }
        },
        {
            "cell_type": "code",
            "source": [
                "from mmlspark.downloader import ModelDownloader\nfrom mmlspark.explainers import *\nfrom mmlspark.cntk import ImageFeaturizer\nfrom mmlspark.stages import UDFTransformer\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nimport numpy as np\nimport pyspark\nimport urllib.request\nimport matplotlib.pyplot as plt\nimport PIL, io\nfrom PIL import Image\n\nvec_access = udf(lambda vec, i: float(vec[i]), FloatType())\nvec_slice = udf(lambda vec, indices: (vec.toArray())[indices].tolist(), ArrayType(FloatType()))\narg_top = udf(lambda vec, n: (-vec.toArray()).argsort()[:n].tolist(), ArrayType(IntegerType()))\n\n\ndef plot_superpixels(image_data, sp_clusters, weights):\n    image_bytes = image_data\n    superpixels = sp_clusters\n    green_value = np.percentile(weights, 80)\n    red_value = np.percentile(weights, 20)\n    img = (PIL.Image.open(io.BytesIO(image_bytes))).convert(\"RGBA\")\n    image_array = np.asarray(img).copy()\n    for (sp, v) in zip(superpixels, weights):\n        if v > green_value:\n            for (x, y) in sp:\n                image_array[y, x, 1] = 255\n                image_array[y, x, 3] = 200\n        if v < red_value:\n            for (x, y) in sp:\n                image_array[y, x, 0] = 255\n                image_array[y, x, 3] = 200\n    plt.clf()\n    plt.imshow(image_array)\n    display()"
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "ae5c16d1-fd1d-466b-9974-9a514f5f0e92"
                }
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "metadata": {
                        "application/vnd.databricks.v1+output": {
                            "data": "",
                            "errorSummary": "",
                            "metadata": {},
                            "errorTraceType": null,
                            "type": "ipynbError",
                            "arguments": {}
                        }
                    },
                    "output_type": "display_data",
                    "data": {
                        "text/html": [
                            "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
                        ]
                    }
                }
            ],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "We download an image for interpretation."
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "54f606d1-f0e1-482c-a363-eec5d040fc12"
                }
            }
        },
        {
            "cell_type": "code",
            "source": [
                "test_image_url = (\n    \"https://mmlspark.blob.core.windows.net/publicwasb/explainers/images/david-lusvardi-dWcUncxocQY-unsplash.jpg\"\n)\nwith urllib.request.urlopen(test_image_url) as url:\n    barr = url.read()\n\nimg = (PIL.Image.open(io.BytesIO(barr))).convert(\"RGBA\")\nimage_array = np.asarray(img).copy()\n\nplt.clf()\nplt.imshow(image_array)\ndisplay()"
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "e3f6ce95-29dc-4caf-b088-22ddd763e090"
                }
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "metadata": {
                        "application/vnd.databricks.v1+output": {
                            "data": "",
                            "errorSummary": "",
                            "metadata": {},
                            "errorTraceType": null,
                            "type": "ipynbError",
                            "arguments": {}
                        }
                    },
                    "output_type": "display_data",
                    "data": {
                        "text/html": [
                            "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
                        ]
                    }
                }
            ],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "Create a dataframe from the downloaded image, and use ResNet50 model to infer the image.\n\nThe result shows 88.7% probability of \"upright piano\", and 9.6% probability of \"cello\"."
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "5bbfae73-8289-49cc-9ddb-212ed3905bbb"
                }
            }
        },
        {
            "cell_type": "code",
            "source": [
                "image_df = spark.createDataFrame([(bytearray(barr),)], [\"image\"])\n\nnetwork = ModelDownloader(spark, \"dbfs:/Models/\").downloadByName(\"ResNet50\")\n\nmodel = ImageFeaturizer(inputCol=\"image\", outputCol=\"probability\", cutOutputLayers=0).setModel(network)\n\npredicted = (\n    model.transform(image_df)\n    .withColumn(\"top2pred\", arg_top(col(\"probability\"), lit(2)))\n    .withColumn(\"top2prob\", vec_slice(col(\"probability\"), col(\"top2pred\")))\n)\n\ndisplay(predicted.select(\"top2pred\", \"top2prob\"))"
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "2eeee2c8-6d20-4c19-ba4a-092c549cccb8"
                }
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "metadata": {
                        "application/vnd.databricks.v1+output": {
                            "data": "",
                            "errorSummary": "",
                            "metadata": {},
                            "errorTraceType": null,
                            "type": "ipynbError",
                            "arguments": {}
                        }
                    },
                    "output_type": "display_data",
                    "data": {
                        "text/html": [
                            "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
                        ]
                    }
                }
            ],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "First we use the LIME image explainer to explain the model's top 2 classes' probabilities."
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "d9785d3d-2d92-4990-bda0-8867bfc5f251"
                }
            }
        },
        {
            "cell_type": "code",
            "source": [
                "lime = (\n    ImageLIME()\n    .setModel(model)\n    .setOutputCol(\"weights\")\n    .setInputCol(\"image\")\n    .setCellSize(50.0)\n    .setModifier(20.0)\n    .setNumSamples(500)\n    .setMetricsCol(\"r2\")\n    .setTargetCol(\"probability\")\n    .setTargetClassesCol(\"top2pred\")\n    .setSamplingFraction(0.7)\n)\n\nlime_result = (\n    lime.transform(predicted)\n    .withColumn(\"weights_piano\", col(\"weights\").getItem(0))\n    .withColumn(\"weights_cello\", col(\"weights\").getItem(1))\n    .withColumn(\"r2_piano\", vec_access(\"r2\", lit(0)))\n    .withColumn(\"r2_cello\", vec_access(\"r2\", lit(1)))\n    .cache()\n)\n\ndisplay(lime_result.select(col(\"weights_piano\"), col(\"r2_piano\"), col(\"weights_cello\"), col(\"r2_cello\")))\nlime_row = lime_result.head()"
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "0a550898-47d1-4e63-acbb-f3ee68d94e4f"
                }
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "metadata": {
                        "application/vnd.databricks.v1+output": {
                            "data": "",
                            "errorSummary": "",
                            "metadata": {},
                            "errorTraceType": null,
                            "type": "ipynbError",
                            "arguments": {}
                        }
                    },
                    "output_type": "display_data",
                    "data": {
                        "text/html": [
                            "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
                        ]
                    }
                }
            ],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "We plot the LIME weights for \"piano\" output and \"cell\" output.\n\nGreen area are superpixels with LIME weights above 90 percentile, and red area are superpixels with LIME weights below 10 percentile."
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "41a48718-30b8-41e8-8dc0-0adedbd3a12d"
                }
            }
        },
        {
            "cell_type": "code",
            "source": [
                "plot_superpixels(barr, lime_row[\"superpixels\"][\"clusters\"], list(lime_row[\"weights_piano\"]))\nplot_superpixels(barr, lime_row[\"superpixels\"][\"clusters\"], list(lime_row[\"weights_cello\"]))"
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "33915bc4-197c-453d-a4fc-3c12c26712c8"
                }
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "metadata": {
                        "application/vnd.databricks.v1+output": {
                            "data": "",
                            "errorSummary": "",
                            "metadata": {},
                            "errorTraceType": null,
                            "type": "ipynbError",
                            "arguments": {}
                        }
                    },
                    "output_type": "display_data",
                    "data": {
                        "text/html": [
                            "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
                        ]
                    }
                }
            ],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "Then we use the Kernel SHAP image explainer to explain the model's top 2 classes' probabilities."
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "578dcfcc-7659-40ff-afad-ebea55f4d870"
                }
            }
        },
        {
            "cell_type": "code",
            "source": [
                "shap = (\n    ImageSHAP()\n    .setModel(model)\n    .setOutputCol(\"shaps\")\n    .setSuperpixelCol(\"superpixels\")\n    .setInputCol(\"image\")\n    .setCellSize(50.0)\n    .setModifier(20.0)\n    .setNumSamples(500)\n    .setMetricsCol(\"r2\")\n    .setTargetCol(\"probability\")\n    .setTargetClassesCol(\"top2pred\")\n)\n\nshap_result = (\n    shap.transform(predicted)\n    .withColumn(\"shaps_piano\", col(\"shaps\").getItem(0))\n    .withColumn(\"shaps_cello\", col(\"shaps\").getItem(1))\n    .withColumn(\"r2_piano\", vec_access(\"r2\", lit(0)))\n    .withColumn(\"r2_cello\", vec_access(\"r2\", lit(1)))\n    .cache()\n)\n\ndisplay(shap_result.select(col(\"shaps_piano\"), col(\"r2_piano\"), col(\"shaps_cello\"), col(\"r2_cello\")))\nshap_row = shap_result.head()"
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "23cf13f4-093e-441d-becf-29c8d1eead0e"
                }
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "metadata": {
                        "application/vnd.databricks.v1+output": {
                            "data": "",
                            "errorSummary": "",
                            "metadata": {},
                            "errorTraceType": null,
                            "type": "ipynbError",
                            "arguments": {}
                        }
                    },
                    "output_type": "display_data",
                    "data": {
                        "text/html": [
                            "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
                        ]
                    }
                }
            ],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "We plot the SHAP values for \"piano\" output and \"cell\" output.\n\nGreen area are superpixels with SHAP values above 90 percentile, and red area are superpixels with SHAP values below 10 percentile.\n\n> Notice that we drop the base value from the SHAP output before rendering the superpixels. The base value is the model output for the background (all black) image."
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "d069a2bd-20f2-4235-93a3-b145f93e2b4e"
                }
            }
        },
        {
            "cell_type": "code",
            "source": [
                "plot_superpixels(barr, shap_row[\"superpixels\"][\"clusters\"], list(shap_row[\"shaps_piano\"][1:]))\nplot_superpixels(barr, shap_row[\"superpixels\"][\"clusters\"], list(shap_row[\"shaps_cello\"][1:]))"
            ],
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "title": "",
                    "showTitle": false,
                    "inputWidgets": {},
                    "nuid": "63c8d593-e336-46d5-94f4-a7466b65bfc7"
                }
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "metadata": {
                        "application/vnd.databricks.v1+output": {
                            "data": "",
                            "errorSummary": "",
                            "metadata": {},
                            "errorTraceType": null,
                            "type": "ipynbError",
                            "arguments": {}
                        }
                    },
                    "output_type": "display_data",
                    "data": {
                        "text/html": [
                            "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
                        ]
                    }
                }
            ],
            "execution_count": 0
        }
    ],
    "metadata": {
        "application/vnd.databricks.v1+notebook": {
            "notebookName": "Interpretability - Image Explainers",
            "dashboards": [],
            "notebookMetadata": {
                "pythonIndentUnit": 2
            },
            "language": "python",
            "widgets": {},
            "notebookOrigID": 496759265154124
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}