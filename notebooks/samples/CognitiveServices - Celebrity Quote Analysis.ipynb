{
  "cells":[
    {
      "cell_type":"markdown",
      "source":[
        "# Automated Captioning Pipeline with Microsoft ML for Apache Spark"
      ],
      "metadata":{

      }
    },
    {
      "cell_type":"code",
      "source":[
        "from mmlspark import *\nfrom pyspark.ml import PipelineModel\nfrom pyspark.sql.functions import col, udf\nfrom pyspark.ml.feature import SQLTransformer\nimport os\n\n#put your service keys here\nTEXT_API_KEY          = os.environ[\"TEXT_API_KEY\"]\nVISION_API_KEY        = os.environ[\"VISION_API_KEY\"]\nFACE_API_KEY          = os.environ[\"FACE_API_KEY\"]\nBING_IMAGE_SEARCH_KEY = os.environ[\"BING_IMAGE_SEARCH_KEY\"]"
      ],
      "metadata":{

      },
      "outputs":[

      ],
      "execution_count":2
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Extracting celebrity quote images using Bing Image Search on Spark\n\nHere we define two Transformers to extract celebrity quote images."
      ],
      "metadata":{

      }
    },
    {
      "cell_type":"code",
      "source":[
        "imgsPerBatch = 10 #the number of images Bing will return for each query\noffsets = [(i*imgsPerBatch,) for i in range(100)] # A list of offsets, used to page into the search results\nbingParameters = spark.createDataFrame(offsets, [\"offset\"])\n\nbingSearch = BingImageSearch()\\\n  .setSubscriptionKey(BING_IMAGE_SEARCH_KEY)\\\n  .setOffsetCol(\"offset\")\\\n  .setQuery(\"celebrity quotes\")\\\n  .setCount(imgsPerBatch)\\\n  .setOutputCol(\"images\")\n\n#Transformer to that extracts and flattens the richly structured output of Bing Image Search into a simple URL column\ngetUrls = BingImageSearch.getUrlTransformer(\"images\", \"url\")"
      ],
      "metadata":{

      },
      "outputs":[

      ],
      "execution_count":4
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Recognizing Images of Celebrities\nThis block identifies the name of the celebrities for each of the images returned by the Bing Image Search."
      ],
      "metadata":{

      }
    },
    {
      "cell_type":"code",
      "source":[
        "celebs = RecognizeDomainSpecificContent()\\\n          .setSubscriptionKey(VISION_API_KEY)\\\n          .setModel(\"celebrities\")\\\n          .setUrl(\"https://eastus.api.cognitive.microsoft.com/vision/v2.0/\")\\\n          .setImageUrlCol(\"url\")\\\n          .setOutputCol(\"celebs\")\n\n#Extract the first celebrity we see from the structured response\nfirstCeleb = SQLTransformer(statement=\"SELECT *, celebs.result.celebrities[0].name as firstCeleb FROM __THIS__\")"
      ],
      "metadata":{

      },
      "outputs":[

      ],
      "execution_count":6
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Reading the quote from the image.\nThis stage performs OCR on the images to recognize the quotes."
      ],
      "metadata":{

      }
    },
    {
      "cell_type":"code",
      "source":[
        "recognizeText = RecognizeText()\\\n  .setSubscriptionKey(VISION_API_KEY)\\\n  .setUrl(\"https://eastus.api.cognitive.microsoft.com/vision/v2.0/recognizeText\")\\\n  .setImageUrlCol(\"url\")\\\n  .setMode(\"Printed\")\\\n  .setOutputCol(\"ocr\")\n\ndef getTextFunction(ocrRow):\n  return \"\\n\".join([line.text for line in ocrRow.recognitionResult.lines])\n\n# this transformer wil extract a simpler string from the structured output of recognize text\ngetText = UDFTransformer().setUDF(udf(getTextFunction)).setInputCol(\"ocr\").setOutputCol(\"text\")\n"
      ],
      "metadata":{

      },
      "outputs":[

      ],
      "execution_count":8
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Understanding the Sentiment of the Quote"
      ],
      "metadata":{

      }
    },
    {
      "cell_type":"code",
      "source":[
        "sentimentTransformer = TextSentiment()\\\n    .setTextCol(\"text\")\\\n    .setUrl(\"https://eastus.api.cognitive.microsoft.com/text/analytics/v2.0/sentiment\")\\\n    .setSubscriptionKey(TEXT_API_KEY)\\\n    .setOutputCol(\"sentiment\")\n\n#Extract the sentiment score from the API response body\ngetSentiment = SQLTransformer(statement=\"SELECT *, sentiment[0].score as sentimentScore FROM __THIS__\")"
      ],
      "metadata":{

      },
      "outputs":[

      ],
      "execution_count":10
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Tying it all together\n\nNow that we have built the stages of our pipeline its time to chain them together into a single model that can be used to process batches of incoming data"
      ],
      "metadata":{

      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Select the final coulmns\ncleanupColumns = SelectColumns().setCols([\"url\", \"firstCeleb\", \"text\", \"sentimentScore\"])\n\ncelebrityQuoteAnalysis = PipelineModel(stages=[\n  bingSearch, getUrls, celebs, firstCeleb, recognizeText, getText, sentimentTransformer, getSentiment, cleanupColumns])\n\ncelebrityQuoteAnalysis.transform(bingParameters).show(5)"
      ],
      "metadata":{

      },
      "outputs":[

      ],
      "execution_count":12
    },
    {
      "cell_type":"code",
      "source":[
        ""
      ],
      "metadata":{

      },
      "outputs":[

      ],
      "execution_count":13
    }
  ],
  "metadata":{
    "name":"Cognitive Services on Spark",
    "notebookId":3150784648673914,
    "anaconda-cloud":{},
    "kernelspec":{
      "display_name":"Python [default]",
      "language":"python",
      "name":"python3"
    },
    "language_info":{
      "codemirror_mode":{
        "name":"ipython",
        "version":3
      },
      "file_extension":".py",
      "mimetype":"text/x-python",
      "name":"python",
      "nbconvert_exporter":"python",
      "pygments_lexer":"ipython3",
      "version":"3.6.3"
    }
  },
  "nbformat":4,
  "nbformat_minor":0
}